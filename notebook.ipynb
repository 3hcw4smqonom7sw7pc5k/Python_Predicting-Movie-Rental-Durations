{"cells":[{"source":"Python 3.8","metadata":{},"cell_type":"markdown","id":"b252459c-e61d-4440-a542-1721c873cf9a"},{"source":"Project Instructions\n\nIn this project, you will use regression models to predict the number of days a customer rents DVDs for.\n\nAs with most data science projects, you will need to pre-process the data provided, in this case, a csv file called rental_info.csv. Specifically, you need to:\n\n    Read in the csv file rental_info.csv using pandas.\n    Create a column named \"rental_length_days\" using the columns \"return_date\" and \"rental_date\", and add it to the pandas DataFrame. This column should contain information on how many days a DVD has been rented by a customer.\n    Create two columns of dummy variables from \"special_features\", which takes the value of 1 when:\n        The value is \"Deleted Scenes\", storing as a column called \"deleted_scenes\".\n        The value is \"Behind the Scenes\", storing as a column called \"behind_the_scenes\".\n    Make a pandas DataFrame called X containing all the appropriate features you can use to run the regression models, avoiding columns that leak data about the target.\n    Choose the \"rental_length_days\" as the target column and save it as a pandas Series called y.\n\nFollowing the preprocessing you will need to:\n\n    Split the data into X_train, y_train, X_test, and y_test train and test sets, avoiding any features that leak data about the target variable, and include 20% of the total data in the test set.\n    Set random_state to 9 whenever you use a function/method involving randomness, for example, when doing a test-train split.\n\nRecommend a model yielding a mean squared error (MSE) less than 3 on the test set\n\n    Save the model you would recommend as a variable named best_model, and save its MSE on the test set as best_mse.","metadata":{},"cell_type":"markdown","id":"7e12026b-e303-4d7b-ac76-3bd40ef895ce"},{"source":"How to approach the project\n\n1. Getting the number of rental days.\n\nNotice that the columns \"return_date\" and \"rental_date\" are not already in a pandas datetime format - you need to convert them into a datetime format.\nHow to convert into datetime format?\n\n    An example to convert the column \"return_date\" in the DataFrame df into datetime format using the syntax pd.to_datetime(df[\"return_date\"]).\n\nHow to get number of rental days?\n\n    Once you have converted \"return_date\" and \"rental_date\" into pandas datetime format, you can get the number of days by using the following code:\n\n\ndf[\"rental_length\"] = pd.to_datetime(df[\"return_date\"]) - pd.to_datetime(df[\"rental_date\"])\ndf[\"rental_length_days\"] = df[\"rental_length\"].dt.days\n\n\n2. Adding dummy variables using the special features column.\n\nOne way of adding dummy variables according to the entries in the \"special_features\" column is using np.where().\nWhat is the code to add the dummy variables?\n\n    If df_rental is the pandas DataFrame read via the csv file, then you can add a dummy variable for \"deleted_scenes\" there using the following syntax df_rental[\"deleted_scenes\"] =  np.where(df_rental[\"special_features\"].str.contains(\"Deleted Scenes\"), 1,0)\n\n3. Executing a train-test split\n\nYou can perform a train-test split by using the train_test_split() function from sklearn.model_selection.\nWhat's the code to do a train-test split?\n\n    If X is the feature matrix and y is the target variable, a train-test split can be performed using the code X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=9).\n    The function train_test_split() also takes the proportion of entries to be in the test set, called test_size, which is 20%, or 0.2, in this case.\n    The random_state keyword argument sets a seed so that the split can be replicated in the future.\n\n4. Performing feature selection\n\nIdentify the features with the best prediction power for the target variable.\nUsing Lasso Regression\n\n    Using Lasso() from sklearn.linear_model allows you to look at feature importance by accessing the model's .coef_ attribute, where values over 0 indicate a contribution to the model's performance.\n    Lasso() can be instantiated by setting random_state to 9 and providing a positive decimal value to the alpha keyword argument for regularization (the lower the number, the weaker the regularization).\n    You can subset the training and test features for columns with non-zero coefficients using .iloc[], keeping all rows and filtering columns using the syntax lasso_coef > 0.\n\n5. Choosing models and performing hyperparameter tuning\n\nTry a variety of regression models.\nFitting models to the data\n\n    You can try models such as LinearRegression(), DecisionTreeRegressor(), and RandomForestRegressor() to estimate the target variable based on the features.\n\nTuning your model\n\n    The RandomizedSearchCV() function allows you to search for the best model performance using random values from ranges of hyperparameters.\n    To use this function you should pass the model object, set the param_distributions keyword argument equal to a dictionary of hyperparameters to search over, set cv equal to the number of folds of cross-validation to perform, and set random_state equal to 9.\n\n6. Predicting values on test set\n\nSince you are using sklearn, you can use the .predict() function of the trained model to get fitted values. The .predict() function takes a feature matrix whose outcome you want to predict as an argument.\nWhat is an example code to predict values?\n\n    In the following code, a linear regression model is being fit where X is the feature matrix and y is the target variable.\n    The .predict() function is used to predict the target variable using features from X:\n    ols = LinearRegression()\n    ols = ols.fit(X, y)\n    y_pred = ols.predict(X)\n\n\n7. Computing mean squared error\n\nYou can use the mean_squared_error() function from sklearn.metrics to compute mean squared error. It takes as input the observed target variable and the predicted target variable.\nHow to compute a model's mean squared error?\n\n    You can use the code mean_squared_error(y, y_pred) to compute mean squared error. Here y is the observed target variable and y_pred is its corresponding predicted values.","metadata":{},"cell_type":"markdown","id":"10c68693-e102-4ca6-8ca0-bff784207439"},{"source":"![dvd_image](dvd_image.jpg)\n\nA DVD rental company needs your help! They want to figure out how many days a customer will rent a DVD for based on some features and has approached you for help. They want you to try out some regression models which will help predict the number of days a customer will rent a DVD for. The company wants a model which yeilds a MSE of 3 or less on a test set. The model you make will help the company become more efficient inventory planning.\n\nThe data they provided is in the csv file `rental_info.csv`. It has the following features:\n- `\"rental_date\"`: The date (and time) the customer rents the DVD.\n- `\"return_date\"`: The date (and time) the customer returns the DVD.\n- `\"amount\"`: The amount paid by the customer for renting the DVD.\n- `\"amount_2\"`: The square of `\"amount\"`.\n- `\"rental_rate\"`: The rate at which the DVD is rented for.\n- `\"rental_rate_2\"`: The square of `\"rental_rate\"`.\n- `\"release_year\"`: The year the movie being rented was released.\n- `\"length\"`: Lenght of the movie being rented, in minuites.\n- `\"length_2\"`: The square of `\"length\"`.\n- `\"replacement_cost\"`: The amount it will cost the company to replace the DVD.\n- `\"special_features\"`: Any special features, for example trailers/deleted scenes that the DVD also has.\n- `\"NC-17\"`, `\"PG\"`, `\"PG-13\"`, `\"R\"`: These columns are dummy variables of the rating of the movie. It takes the value 1 if the move is rated as the column name and 0 otherwise. For your convinience, the reference dummy has already been dropped.","metadata":{},"id":"b4ae5707-109f-4cd6-8168-88cac0179d6b","cell_type":"markdown"},{"source":"# Start your coding from below\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# For lasso\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Run OLS\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Random forest\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Read in data\ndf_rental = pd.read_csv(\"rental_info.csv\")\n\n# Add information on rental duration\ndf_rental[\"rental_length\"] = pd.to_datetime(df_rental[\"return_date\"]) - pd.to_datetime(df_rental[\"rental_date\"])\ndf_rental[\"rental_length_days\"] = df_rental[\"rental_length\"].dt.days\n\n### Add dummy variables\n# Add dummy for deleted scenes\ndf_rental[\"deleted_scenes\"] =  np.where(df_rental[\"special_features\"].str.contains(\"Deleted Scenes\"), 1, 0)\n# Add dummy for behind the scenes\ndf_rental[\"behind_the_scenes\"] =  np.where(df_rental[\"special_features\"].str.contains(\"Behind the Scenes\"), 1, 0)\n\n# Choose columns to drop\ncols_to_drop = [\"special_features\", \"rental_length\", \"rental_length_days\", \"rental_date\", \"return_date\"]\n\n# Split into feature and target sets\nX = df_rental.drop(cols_to_drop, axis=1)\ny = df_rental[\"rental_length_days\"]\n\n# Further split into training and test data\nX_train,X_test,y_train,y_test = train_test_split(X, \n                                                 y, \n                                                 test_size=0.2, \n                                                 random_state=9)\n\n# Create the Lasso model\nlasso = Lasso(alpha=0.3, random_state=9) \n\n# Train the model and access the coefficients\nlasso.fit(X_train, y_train)\nlasso_coef = lasso.coef_\n\n# Perform feature selectino by choosing columns with positive coefficients\nX_lasso_train, X_lasso_test = X_train.iloc[:, lasso_coef > 0], X_test.iloc[:, lasso_coef > 0]\n\n# Run OLS models on lasso chosen regression\nols = LinearRegression()\nols = ols.fit(X_lasso_train, y_train)\ny_test_pred = ols.predict(X_lasso_test)\nmse_lin_reg_lasso = mean_squared_error(y_test, y_test_pred)\n\n# Random forest hyperparameter space\nparam_dist = {'n_estimators': np.arange(1,101,1),\n          'max_depth':np.arange(1,11,1)}\n\n# Create a random forest regressor\nrf = RandomForestRegressor()\n\n# Use random search to find the best hyperparameters\nrand_search = RandomizedSearchCV(rf, \n                                 param_distributions=param_dist, \n                                 cv=5, \n                                 random_state=9)\n\n# Fit the random search object to the data\nrand_search.fit(X_train, y_train)\n\n# Create a variable for the best hyper param\nhyper_params = rand_search.best_params_\n\n# Run the random forest on the chosen hyper parameters\nrf = RandomForestRegressor(n_estimators=hyper_params[\"n_estimators\"], \n                           max_depth=hyper_params[\"max_depth\"], \n                           random_state=9)\nrf.fit(X_train,y_train)\nrf_pred = rf.predict(X_test)\nmse_random_forest= mean_squared_error(y_test, rf_pred)\n\n# Random forest gives lowest MSE so:\nbest_model = rf\nbest_mse = mse_random_forest\n\n# Congratulations, you completed the project!","metadata":{"executionCancelledAt":null,"executionTime":23009,"lastExecutedAt":1733452190275,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start your coding from below\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# For lasso\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Run OLS\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Random forest\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Read in data\ndf_rental = pd.read_csv(\"rental_info.csv\")\n\n# Add information on rental duration\ndf_rental[\"rental_length\"] = pd.to_datetime(df_rental[\"return_date\"]) - pd.to_datetime(df_rental[\"rental_date\"])\ndf_rental[\"rental_length_days\"] = df_rental[\"rental_length\"].dt.days\n\n### Add dummy variables\n# Add dummy for deleted scenes\ndf_rental[\"deleted_scenes\"] =  np.where(df_rental[\"special_features\"].str.contains(\"Deleted Scenes\"), 1, 0)\n# Add dummy for behind the scenes\ndf_rental[\"behind_the_scenes\"] =  np.where(df_rental[\"special_features\"].str.contains(\"Behind the Scenes\"), 1, 0)\n\n# Choose columns to drop\ncols_to_drop = [\"special_features\", \"rental_length\", \"rental_length_days\", \"rental_date\", \"return_date\"]\n\n# Split into feature and target sets\nX = df_rental.drop(cols_to_drop, axis=1)\ny = df_rental[\"rental_length_days\"]\n\n# Further split into training and test data\nX_train,X_test,y_train,y_test = train_test_split(X, \n                                                 y, \n                                                 test_size=0.2, \n                                                 random_state=9)\n\n# Create the Lasso model\nlasso = Lasso(alpha=0.3, random_state=9) \n\n# Train the model and access the coefficients\nlasso.fit(X_train, y_train)\nlasso_coef = lasso.coef_\n\n# Perform feature selectino by choosing columns with positive coefficients\nX_lasso_train, X_lasso_test = X_train.iloc[:, lasso_coef > 0], X_test.iloc[:, lasso_coef > 0]\n\n# Run OLS models on lasso chosen regression\nols = LinearRegression()\nols = ols.fit(X_lasso_train, y_train)\ny_test_pred = ols.predict(X_lasso_test)\nmse_lin_reg_lasso = mean_squared_error(y_test, y_test_pred)\n\n# Random forest hyperparameter space\nparam_dist = {'n_estimators': np.arange(1,101,1),\n          'max_depth':np.arange(1,11,1)}\n\n# Create a random forest regressor\nrf = RandomForestRegressor()\n\n# Use random search to find the best hyperparameters\nrand_search = RandomizedSearchCV(rf, \n                                 param_distributions=param_dist, \n                                 cv=5, \n                                 random_state=9)\n\n# Fit the random search object to the data\nrand_search.fit(X_train, y_train)\n\n# Create a variable for the best hyper param\nhyper_params = rand_search.best_params_\n\n# Run the random forest on the chosen hyper parameters\nrf = RandomForestRegressor(n_estimators=hyper_params[\"n_estimators\"], \n                           max_depth=hyper_params[\"max_depth\"], \n                           random_state=9)\nrf.fit(X_train,y_train)\nrf_pred = rf.predict(X_test)\nmse_random_forest= mean_squared_error(y_test, rf_pred)\n\n# Random forest gives lowest MSE so:\nbest_model = rf\nbest_mse = mse_random_forest\n\n# Congratulations, you completed the project!","lastExecutedByKernel":"acfdf77d-4bd8-485f-ac0f-2e0b358eb5ab"},"id":"a7ede566-910a-445c-b11a-68d192ac8506","cell_type":"code","execution_count":3,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}